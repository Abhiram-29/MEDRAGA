{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6272f68-a8ad-469b-934c-7dc0702438f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_cohere import CohereEmbeddings , CohereRerank , ChatCohere\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "import cohere\n",
    "import qdrant_client\n",
    "from qdrant_client.models import Batch\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af83c4a7-2a3f-4b23-9cbb-02ded848abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "Qclient = QdrantClient(url=\"http://localhost:6333\")\n",
    "cohere_client = cohere.Client()\n",
    "client = qdrant_client.QdrantClient(os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee88bed3-e6be-4ceb-87c6-03e7ec1ebb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohereIndexing(client,collection,texts):\n",
    "    client.upsert(\n",
    "    collection_name=collection,\n",
    "    points=Batch(\n",
    "        ids=range(len(texts)),\n",
    "        vectors=cohere_client.embed(\n",
    "            model=\"embed-english-v3.0\",  # New Embed v3 model\n",
    "            input_type=\"search_document\",  # Input type for indexing documents\n",
    "            texts= [texts[i].page_content for i in range(len(texts))],\n",
    "        ).embeddings,\n",
    "        payloads = [{\"Context{}\".format(index): value} for index, value in enumerate([texts[i].page_content for i in range(len(texts))], start=1)],\n",
    "    ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff93cc3-87b0-404a-8987-03223508c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohereRetrival(collection,textList):\n",
    "    cohere_client = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
    "    client = qdrant_client.QdrantClient()\n",
    "    result = client.search(\n",
    "    collection_name=collection,\n",
    "    query_vector=cohere_client.embed(\n",
    "        model=\"embed-english-v3.0\",  \n",
    "        input_type=\"search_query\",  # Input type for search queries\n",
    "        texts=textList,\n",
    "    ).embeddings[0],\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d739ba50-bb83-42f1-886c-e110ac79a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"You are a medical assistant that specializes in providing second opinions, diagnosing complex cases \n",
    "and suggesting treatment plans. When I describe the patient details, medical context and task, give me the appropriate treatment plan \n",
    "or second opinion based on the task given by analyzing the patient details and medical context. In your answer include how your opinion or treatment\n",
    "plann is related to the patient's history.\n",
    "\n",
    "Patient History : {patientHistory}\n",
    "\n",
    "Medical Context : {context}\n",
    "\n",
    "Task: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07fefabc-5fc6-44b9-8017-b3ec79ddcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "429e6249-edb4-4476-8860-39805d3bacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = cohereRetrival(\"MedicalPapers\",[question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "299a6741-df5c-4982-b627-84e1b0d9f987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 \\n 2.3 It should take place face to face in a confidential environment, with access for relatives and \\nallied health professionals with a minimum time of 15 -20 minutes. Patients will often be \\nmonths  or even years after injury and frustrated by the delay in diagnosis. It may be the first \\ntime the diagnosis is made, but equally they may already have researched the diagnosis and \\nmade  a decision on their preferred treatment. This decision may change foll owing the \\nconsultation.  \\n \\n2.4 Past medical records from hospital and general practitioner including imaging (if any) should \\nbe available.  \\n \\n2.5 The history of the injury, subsequent and current symptoms should be documented, followed \\nby a clinical examination and re view of all imaging. Instrumented laxiometry may be helpful \\nbut is not considered to be universally necessary.  \\n 2.6 A management plan is made after discussion of both operative & non -operative options for'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[0].payload['Context813']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb88e2-3ab2-432e-b9aa-2c24e7305e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"context\":retrievedDocs[0].payload['Context722'] , \"patientHistory\":\"\",\"question\":question})\n",
    "to_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab86d7-5885-400b-96ac-dad354750198",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"context\":context , \"patientHistory\":patientHistory,\"question\":question})\n",
    "to_markdown(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e139513e-5709-496e-b19f-3fa99e48ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationLLm =  ChatGoogleGenerativeAI(model=\"gemini-1.0-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cf30637-b885-422d-a214-45dcb7d04024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(model,prompt, num_queries):\n",
    "  query_generation_prompt = ChatPromptTemplate.from_template(\"Given the prompt: '{prompt}', generate {num_queries} questions that are better articulated. Return in the form of an list. For example: ['question 1', 'question 2', 'question 3']\")\n",
    "  query_generation_chain = query_generation_prompt | model\n",
    "  return query_generation_chain.invoke({\"prompt\": prompt, \"num_queries\": num_queries}).content.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91cda725-0c04-4e70-9b1f-d4fe7e0e160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'My patient has had a full ACL reconstruction and repair following an ACL tear and a partial meniscus tear. To help him recover fully, what steps are required? How should we prevent a retear of the ACL ligament?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc84de34-4176-4873-8b47-7c1342cb1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = generate_queries(evaluationLLm,question,3)\n",
    "retrievedDocs = cohereRetrival(\"MedicalPapers\",queries[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "929f4edc-87eb-4d53-a067-7277518f553e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What are the essential stages of rehabilitation to optimize recovery after ACL reconstruction and meniscus repair?',\n",
       " '2. How can we effectively prevent a retear of the ACL ligament during the rehabilitation process?',\n",
       " '3. What are the specific precautions and adaptations required to minimize the risk of retear during functional activities post-rehabilitation?']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3328bb06-f28f-41e1-8397-652f3e3f35bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrievedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2b82c-f63f-4b3f-8911-043d142575ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievedDocs[0].payload.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "739ed0ee-6cec-46f2-b6c0-b3dee2db7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohereRetrival(collection,textList):\n",
    "    cohere_client = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
    "    client = qdrant_client.QdrantClient()\n",
    "    result = client.search(\n",
    "    collection_name=collection,\n",
    "    query_vector=cohere_client.embed(\n",
    "        model=\"embed-english-v3.0\",  \n",
    "        input_type=\"search_query\",  # Input type for search queries\n",
    "        texts=textList,\n",
    "    ).embeddings[0],\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "805a478f-64aa-48d7-af9b-e99dc394fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponce(prompt,context = \"\",PatientHistory=\"\"):\n",
    "    result = chain.invoke({\"context\":context,\"patientHistory\":PatientHistory,\"question\":prompt})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b8853507-ed5c-4c7c-81f2-26a5ab0d6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "def ragFusion(prompt,collection= \"MedicalPapers\"):\n",
    "    co = cohere.Client(os.environ[\"COHERE_API_KEY\"])\n",
    "    queryGenerationPrompt = ChatPromptTemplate.from_template(\"Given the prompt: '{prompt}', generate {num_queries} questions that are better articulated. Return in the form of an list. For example: ['question 1', 'question 2', 'question 3']\")\n",
    "    queryGenerationChain = queryGenerationPrompt | llm\n",
    "    queries = queryGenerationChain.invoke({\"prompt\": prompt, \"num_queries\": 3}).content.split('\\n')\n",
    "    retrievedContent = []\n",
    "    for query in queries:\n",
    "        ret = cohereRetrival(collection,[query])\n",
    "        for doc in ret:\n",
    "            for key,value in doc.payload.items():\n",
    "                value = value.replace(u'\\xa0',u' ')\n",
    "                value = value.replace(u'\\t',u'  ')\n",
    "                value = value.replace(u'\\r',u'')\n",
    "                value = value.replace(u'\\n',u'      ')\n",
    "                retrievedContent.append(value)\n",
    "    retrievedContent = list(set(retrievedContent))\n",
    "    result = co.rerank(model=\"rerank-english-v3.0\", query=prompt, documents=retrievedContent, top_n=5, return_documents=True)\n",
    "    context = \"\"\n",
    "    for i in result.results:\n",
    "        context += i.document.text\n",
    "        print(i.document)\n",
    "        context += \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b093a15a-3f86-4a70-825c-8adf5904a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_core.runnables import (\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough\n",
    ")\n",
    "\n",
    "import qdrant_client\n",
    "\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "\n",
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-light-v3.0\",\n",
    "    cohere_api_key=os.environ[\"COHERE_API_KEY\"]\n",
    ")\n",
    "\n",
    "doc_store = Qdrant(\n",
    "    client=client, collection_name=\"MedicalPapers\", \n",
    "    embeddings=embeddings,\n",
    ")\n",
    "\n",
    "retriever = doc_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "717f04be-2db2-4a97-babb-20c2fed9c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "template = \"\"\"You are a medical assistant that specializes in providing second opinions, diagnosing complex cases \n",
    "and suggesting treatment plans. When I describe the patient details, medical context and task, give me the appropriate treatment plan \n",
    "or second opinion based on the task given by analyzing the patient details and medical context. In your answer include how your opinion or treatment\n",
    "plann is related to the patient's history.\n",
    "\n",
    "Patient History : {patientHistory}\n",
    "\n",
    "Medical Context : {context}\n",
    "\n",
    "Task: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8e9d26-153a-4830-b738-c2437916d4ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1778620258.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    retrival = RunnableParallel( \"context\": retriever,\"question\": RunnablePassthrough(), \"Patient History\": RunnablePassthrough())\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "retrival = RunnableParallel( \"context\": retriever,\"question\": RunnablePassthrough(), \"Patient History\": RunnablePassthrough())\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = retrival | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08582469-8e21-42cc-81f1-5fe87a1922f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
